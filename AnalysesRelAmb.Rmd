---
Author: Thomas Verliefde
Date: '2019-04-25'
Output: html_document
Title: Analyses RelAmb
editor_options:
  chunk_output_type: console
version: '1.1'
---

TODO: Check all variables whether they are what they should be (factor, numeric, ...)
TODO: Additional analysis with control variables (keyfirst, otherfirst, gender, ...)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
load("20190426.RData")

# save.image("20190426.RData")
```

```{r libraries, include=FALSE}
lapply(
  c("plyr","dplyr","tidyr","ggplot2","readxl","readr","lme4","afex","lmerTest","emmeans",
    "pbkrtest","purrr","magrittr","cowplot","nnet"),
  require,
  character.only = T
)
```

#############################
# Importing & Cleaning Data #
#############################

Make sure the relevant datafiles (Data_RelAmb.zip and BAWL-R.xls) are in the working directory.

```{r BAWL-R.xls, options}

bawl <- "BAWL-R.xls" %>% read_excel %>%
  mutate(
    WORD_CLASS = recode(
      WORD_CLASS,
      "N" = "NOUN",
      "V" = "VERB",
      "A" = "ADJ"
    )
  )


```

```{r Data_RelAmb.zip, include=FALSE}

temp <- tempdir()
df_raw <- "Data_RelAmb.zip" %>% {
  ldply(
    .data = unzip(.,list=T) %>% # unzip the 
      filter(grepl("(.csv)$",.$Name)) %>% # Ignore any file/folder that is not a .csv file
      arrange(Name %>% desc) %$% Name, # Returns a 'list' containing the relevant .csv filenames
    .fun = function(x) unzip(.,files=x,exdir=temp) %>% read_csv
  )
}
rm(temp)

```


```{r Single File Extract, include = FALSE}

# temp <- tempdir()
# df_test <- "Data_RelAmb.zip" %>% 
#   unzip(.,files=unzip(.,list=T) %>% filter(grepl("(.csv)$",.$Name)) %>% extract(1,1), exdir=temp) %>%
#   read_csv
# rm(temp)
# 
# df_test %>% glimpse
# unzip("Data_RelAmb.zip",list=T) %>% filter(grepl("(.csv)$",.$Name)) %>% extract(1,1)

```

```{r Data_RelAmb.zip, include=FALSE}

temp <- tempdir()
df_rawTime <- "Data_RelAmb.zip" %>% {
  ldply(
    .data = unzip(.,list=T) %>% # unzip the 
      filter(grepl("(.csv)$",.$Name)) %>% # Ignore any file/folder that is not a .csv file
      arrange(Name %>% desc) %$% Name, # Returns a 'list' containing the relevant .csv filenames
    .fun = function(x) unzip(.,files=x,exdir=temp) %>%
      read_csv(col_names=FALSE,skip=1) %>% select(1,(dim(.)[2]-12):dim(.)[2])
  ) %>% select(sort(current_vars())) %>% {
    bind_cols(
      filter(.,X756 %>% is.na) %>% select(-X756) %>% t %>% as_tibble,
      filter(.,X769 %>% is.na) %>% select(-X769) %>% t %>% as_tibble
    ) } %>% t %>% as_tibble %>% select(-14) %>% mutate_at(vars(-1),as.numeric) %>%
      mutate_at(vars(-1),function(x) format(x,scientific=FALSE)) %>%
    mutate_at(vars(seq(3,13,2)), function(x) gsub("( *)(\\d+)",".\\2",x)) %>%
    mutate_all(as.numeric) %$% 
      bind_cols(
        select(.,V1),
        list(extract(.,seq(2,12,2)),extract(.,seq(3,13,2))) %>% pmap(add) %>% as_tibble
      ) %>%
    rename(
      Subject = V1,
      timeOther = V2,
      timePractice = V4,
      timeExperiment = V6,
      timeExplicit = V8,
      timeDemographics = V10,
      timeTotal = V12
    )
}
rm(temp)

```



This part cleans the data up a lot, and puts it in an useable long format.

A few variables are dropped, as they are not crucial for the current investigations.
The data for each trial (both practice and experiment) is put in long format.
The data for each significant other is put in long format.
The information about block(practice/experiment), trialnr, and descriptives (Answer,Prime, primeType, Target, targetType, RT).
Descriptives is spread out again, to have columns for each.
Some variables are renamed.
Some variables are mutated:
  Many are transformed to strings or numericals
  primeType & targetType get clear non-numerical labels
  primeValence is created to reflect the valence of the primes (regardless of nouns or others)
  Condition shows congruent or incongruent trials (or base, for neutral stimuli)
  Correct indicates whether the target was correctly classified
  Inclusion sets whether or not the trial should be included
    Note: we should still implement exclusion of low acc participants # tried implementing, not yet ready
  LogRT is a simple transformation of RT to it's natural logarithm.

```{r cleaning & gathering, options}

df <- df_raw %>% 
  select(
    -c(practicePrimes,practiceTrials,experimentPrimes,experimentTrials,timeOther:dim(.)[2])
  ) %>%
  gather(
    "fullTrials",
    "trialsOutput",
    matches("^([a-z])+_(\\d)+_([a-z])+$") # This regex matches things with structure: abcd*_123*_abcd*
  ) %>%
  gather(
    "fullOthers",
    "otherOutput",
    matches("^(other)(Pos|Neg)(1|2)") # This regex matches: otherPos1*, otherPos2*¨, otherNeg1*, or otherNeg2*
  ) %>%
  separate(
    fullTrials,
    c("Block","Trial","Desc"),
    sep = "_"
  ) %>%
  spread(
    key = Desc, value = trialsOutput
  ) %>%
  separate(
    fullOthers,
    c("otherValence","Desc"),
    sep = "_",
    extra = "merge",
    fill = "right"
  ) %>%
  mutate(
    Desc = Desc %>% replace_na("otherNames") # alternatively, we could use coalesce.
  ) %>%
  spread(
    key = Desc, value = otherOutput
  ) %>%
  gather(
    "otherDir",
    "valDir",
    matches("^(Dir_)")
  ) %>%
  gather(
    "otherSRI",
    "valSRI",
    matches("^(SRI_)")
  ) %>%
  mutate_at(
    vars(otherDir,otherSRI),
    funs(gsub("(^.{4})|(\\d)","",.))
  ) %>%
  separate(
    otherSRI,
    c("SRIValence"),
    sep = "_",
    extra = "drop",
    remove=FALSE
  ) %>%
  rename(
    Answer = answer,
    Prime = prime,
    primeType = primeCat,
    Target = target,
    targetType = targetCat,
    otherNum = Num,
    otherRel = Rel,
    RT = time
  ) %>%
  mutate_at(
    vars(Subject,Trial,RT,Age,otherNum,valDir,valSRI),
    as.numeric
  ) %>%
  group_by(Subject,Block) %>%
  mutate(
    Gender = recode(
      Gender,
      "männlich" = "male",
      "weiblich" = "female"
    ),
    Language = recode(
      Language,
      "Deutsch" = "germanLang",
      "Sonstiges" = "otherLang"
    ),
    Handedness = recode(
      Handedness,
      "rechts" = "rightHand",
      "links" = "leftHand",
      "beide" = "bothHands"
    ),
    primeType = recode(
      primeType,
      `0`= "nounPos",
      `1`= "nounNeg",
      `2`= "otherPos",
      `3`= "otherNeg",
      `4`= "letterStr"
    ) %>% as.factor,
    targetType = recode(
      targetType,
      `0` = "adjPos",
      `1` = "adjNeg"
    ),
    primeValence = case_when(
      grepl("Pos$",primeType) ~ "Pos",
      grepl("Neg$",primeType) ~ "Neg",
      TRUE ~ "Base"
    ) %>% as.factor,
    SRIValence = recode(
      SRIValence,
      "Pos" = "Helpful",
      "Neg" = "Upsetting"
    ),
    primeSource = gsub("^(noun|other|letter)(Pos|Neg|Str)$","\\1",primeType) %>% as.factor,
    otherValence2 = gsub("^(other)(Pos|Neg)(\\d)$","\\2",otherValence),
    Condition = case_when(
      primeValence == "Pos" & targetType == "adjPos" ~ "Congruent",
      primeValence == "Neg" & targetType == "adjNeg" ~ "Congruent",
      primeValence == "Base" ~ "Base",
      TRUE ~ "Incongruent"
    ) %>% as.factor,
    Condition2 = interaction(
      primeSource,Condition,drop=TRUE,sep="",lex.order=TRUE
    ),
    lagPrime = case_when(
      lag(primeType) == primeType~ "Congruent",
      TRUE ~ "Incongruent"),
    lagSource = case_when(
      lag(primeSource) == primeSource~ "Congruent",
      TRUE ~ "Incongruent"),
    lagValence = case_when(
      lag(primeValence) == primeValence~ "Congruent",
      TRUE ~ "Incongruent"),
    lagCondition = case_when(
      lag(Condition) == Condition ~ "Congruent",
      TRUE ~ "Incongruent"),
    Correct = case_when(
      Key == "Apos" & targetType == "adjPos" & Answer == "A" ~ TRUE,
      Key == "Apos" & targetType == "adjNeg" & Answer == "L" ~ TRUE,
      Key == "Aneg" & targetType == "adjNeg" & Answer == "A" ~ TRUE,
      Key == "Aneg" & targetType == "adjPos" & Answer == "L" ~ TRUE,
      TRUE ~ FALSE),
    Accuracy = mean(Correct), # Because we grouped by subject, these means are computed by subject
    # speedInclusion = (RT >= 300 & RT <= 3000), # Trials with latencies < 300 and > 3000 were excluded
    # accInclusion = (1 - mean(speedInclusion)) < 0.83,
    #   # If we have to exclude more than 83% of the trials of a single participant,
    #   #  then this participant will be excluded entirely.
    # nameExclusion = (Subject == 8 | Subject == 72),
    # # These two participants did not follow instructions, as they did not provide sufficient 
    # #  and actual names for SOs as they were instructed to do.
    # # Specifically, one participant provided us with 'Niemanden' (nobody in German),
    # #  the other participant provided weird nicknames, not proper names.
    # subjExclusion = not(accInclusion) | nameExclusion,
    # Exclusion = not(speedInclusion) & not(accInclusion) & nameExclusion,
    # Inclusion = Correct & not(Exclusion),
    logRT = log(RT)
  ) %>% 
  left_join(
      group_by(.,Subject,otherValence,SRIValence,otherValence2) %>%
        summarise(AvgSRI = mean(valSRI)) %>%
        spread(SRIValence,AvgSRI) %>%
        mutate(
          catSRI = case_when(
            Helpful  > 1 & Upsetting == 1 ~ "supportive",
            Helpful  > 1 & Upsetting  > 1 ~ "ambivalent",
            Helpful == 1 & Upsetting  > 1 ~ "aversive",
            Helpful == 1 & Upsetting == 1 ~ "indifferent",
            TRUE ~ NA_character_
          ),
          #         The SRI was developed by Campo and colleagues (2009).
          # They determined categories of network ties:
          # * supportive  ->  >1 on helpful, =1 on upsetting
          # * ambivalent  ->  >1 on helpful, >1 on upsetting
          # * aversive    ->  =1 on helpful, >1 on upsetting
          # * indifferent ->  =1 on helpful, =1 on upsetting
          # 
          # The authors further mention also using a cut-off at 3 rather than 1.
          catSRI_ext = case_when(
            Helpful >= 3 & Upsetting <  3 ~ "supportive",
            Helpful >= 3 & Upsetting >= 3 ~ "ambivalent",
            Helpful <  3 & Upsetting >= 3 ~ "aversive",
            Helpful <  3 & Upsetting <  3 ~ "indifferent",
            TRUE ~ NA_character_
          )
        ) %>% ungroup %>% select(Subject,otherValence,catSRI,catSRI_ext),
      by=c("Subject","otherValence")
  ) %>%
  ungroup %>%
  arrange(Subject)

```

These are all our exclusion variables, split from the main mutate block above, to keep a clear overview.

```{r Exclusion Criteria, options}

df %<>% mutate(
  speedInclusion = (RT >= 300 & RT <= 3000), # Trials with latencies < 300 and > 3000 were excluded
  accInclusion = (1 - mean(speedInclusion & Correct)) < 0.83,
  # If we have to exclude more than 83% of the trials of a single participant,
  #  then this participant will be excluded entirely.
  nameExclusion = (Subject %in% c(8,72)),
  # These participants did not follow instructions, as they did not provide sufficient 
  #  and actual names for SOs as they were instructed to do.
  # Specifically, one participant provided us with 'Niemanden' (nobody in German),
  #  the other participant provided weird nicknames, not proper names.
  # valExclusion = (Subject %in% c(34,58)),
  # These participants did not follow instructions, as they did not provide positive and negative SOs.
  # They provided 4 positive participants (derived from their direct measures), instead of 2 positive and 2 negative.
  instrExclusion = nameExclusion, # | valExclusion,
  subjExclusion = not(accInclusion) | instrExclusion,
  trialInclusion = speedInclusion & Correct,
  Inclusion = trialInclusion & not(subjExclusion)
  )

```

This part creates a few subdataframes, to keep overview and reduce the amount of replicated rows.
[over 666.000 observations in "df" due to multiple "gatherings"]

```{r Specific Dataframes, options}

df_subj <- df %>% filter(Block == "experiment") %>%
  select(
    Subject,Age,Gender,Language,Handedness,Accuracy,subjExclusion,instrExclusion,Study,Key,FirstOthers
  ) %>% distinct %>% arrange(Subject)

df_others <- df %>% filter(Block == "experiment") %>%
  select(
    Subject,Gender,otherValence,otherValence2,otherNames,otherRel,otherNum,otherDir,
    valDir,SRIValence,otherSRI,valSRI,subjExclusion,Study,Key,FirstOthers,catSRI,catSRI_ext
  ) %>% distinct %>% arrange(Subject)

df_val <- df_others %>% filter(subjExclusion %>% not) %>%
  distinct(Subject,otherValence,otherValence2,otherDir,valDir,
           SRIValence,otherSRI,valSRI,catSRI,catSRI_ext)

df_time <- df %>% filter(Block == "experiment") %>%
  select(
    Subject,Gender,subjExclusion,accInclusion,Accuracy
  ) %>% distinct %>% arrange(Subject) %>%
  full_join(df_rawTime,by="Subject")

df_trials <- df %>% filter(Block == "experiment") %>%
  select(
    Subject,Trial,RT,logRT,Prime,primeType,primeSource,primeValence,Target,targetType,
    Condition,Condition2,Answer,Correct,speedInclusion,accInclusion,subjExclusion,
    nameExclusion,trialInclusion,Inclusion,Accuracy,Gender,Key,FirstOthers,Handedness,otherValence
  ) %>% distinct %>% arrange(Subject,Trial)

df_base <- df_raw %>% select(c(practicePrimes,experimentPrimes))

```

#######################
# Demographics & More #
#######################

```{r Inclusions, options}

df_trials %>% group_by(Subject) %>% summarize(
  "excl" = Correct %>% not %>% mean(na.rm=T)
) %$% mean(excl) %>% multiply_by(100) %>% signif(5) %>%
  paste0(.,"% of trials were excluded because they were incorrectly categorized.")

df_trials %>% group_by(Subject) %>% summarize(
  "excl" = speedInclusion %>% not %>% mean(na.rm=T)
) %$% mean(excl) %>% multiply_by(100) %>% signif(5) %>%
  paste0(.,"% of trials were excluded because the response latencies were either too short (<300ms), or too long (>3000ms)") %>%
  cat

df_subj %$% sum(accInclusion %>% not) %>%
  paste("A total of",.,"participants were fully excluded due to extremes in accuracy and/or latency.") %>%
  cat

df_subj %$% sum(subjExclusion) %>%
  paste("A total of",.,"participants were fully excluded due to not following instructions.") %>%
  cat

df_trials %>% filter(!subjExclusion) %>% group_by(Subject) %>% summarize("trialInclusion" = Inclusion %>% mean) %>%
  summarize(trialInclusion %>% mean) %>% as.numeric %>% multiply_by(100) %>% signif(5) %>%
  paste0("In total, ",.,"% of all trials from included participants were included.") %>%
  cat

```

```{r Gender; Language; & Handedness, options}

df_subj %>% filter(accInclusion & !subjExclusion) %>% {
  bind_rows(
    count(., "Var" = "Total"),
    count(., "Var" = Gender),
    count(., "Var" = Language),
    count(., "Var" = Handedness)
  )
} %>% mutate(
  "%" = extract2(.,1,"n") %>%
    divide_by(n,.) %>%
    multiply_by(100) %>%
    signif(4)
)

```

```{r Age & Accuracy, options}

df_subj %>% filter(accInclusion & !subjExclusion) %>% 
  summarize_at(
    vars(Age,Accuracy),
    funs(mean,sd,min,max,median,.args = list(na.rm=T))
  ) %>% gather("Var","Value") %>%
  separate(Var,c("Var","Func"),sep="_") %>%
  spread(Func,Value) %>% select(Var,mean,sd,min,max,median) %>% as.data.frame

```

```{r Control Variables, options}

df_subj %>% filter(accInclusion & !subjExclusion) %>% count(Key,FirstOthers) %>%
  mutate("%" = n %>% divide_by(sum(.)) %>% multiply_by(100))

```

```{r Specific Timings Experiment Duration, options}

df_time %>% filter(accInclusion & !subjExclusion) %>%
  summarize_at(
    vars(starts_with("time")),
    funs(mean,sd,min,max,.args=list(na.rm=T))
  ) %>% gather("Var","Value") %>%
  separate(Var,c("Var","Func"),sep="_") %>%
  spread(Func,Value) %>% select(Var,mean,sd,min,max) %>%
  slice(c(4,5,2,3,1,6)) %>% as.data.frame

```

```{r legacy code, eval=FALSE, include=FALSE}

# This code is only here because I am really proud of it, at least the sapply within select.
# It is utterly outdated

# df %>% mutate(pointTime = gsub("^(.*)$","time\\1",pointTime)) %>%
#   distinct(Subject,pointTime,valTime,subjInclusion) %>%
#   spread(pointTime,valTime) %>%
#   filter(Subject %>% duplicated %>% not & subjInclusion) %>%
#   summarize_at(
#     vars(matches("^time")),
#     funs(mean,sd,min,max,.args=list(na.rm=T))
#   ) %>% select(
#     sapply(
#       c("Other","Practice","Experiment","Explicit","Demographics","Total"),
#       matches
#     ) # I am actually suprised that this works...
#   ) %>% gather("Var","Value") %>% separate(Var,c("Var","Func"),sep="_") %>%
#   spread(Func,Value) %>% select(Var,mean,sd,min,max)

```


######################
# Significant Others #
######################


```{r Names, options}

df_others %>% group_by(otherNames,Subject) %>%
  summarize("otherNum" = otherNum %>% mean(na.rm=T)) %>%
  summarize("n" = n(),"otherNum" = otherNum %>% mean(na.rm=T)) %>%
  add_count(n) %>% arrange(nn %>% desc)

df_others %>% group_by(otherNames,Subject) %>% filter(!is.na(otherNum)) %>%
  summarize(
    "otherNum" = otherNum %>% mean(na.rm=T),
    "otherMax" = otherNum %>% max()
    ) %>% summarize_at(vars(otherNum,otherMax),funs(mean,max,.args=list(na.rm=T)))
  summarize("n" = n(), "otherNum" = otherNum %>% mean(na.rm=T)) %>%
  

```

```{r repeated names within participants, options}

df_others %>% distinct(otherNames,Subject) %>%
  group_by(Subject) %>%
  filter(otherNames %>% substr(1,1) %>% {or(duplicated(.),duplicated(.,fromLast=T))}) # %T>% View

```

```{r Repeated Names between Participants, options}

# The following code shows a list of all names used by our included participants
#View(df_others %>% filter(subjExclusion) %>% distinct(otherNames) %>% arrange(otherNames))

df_others %>% distinct(otherNames,Subject) %>% count(otherNames) %>% count(n)

df_others %>% distinct(otherNames,Subject) %>% count(otherNames) %>% filter(n > 1) %>% arrange(desc(n))

```

By checking all the names, there are a few issues:

Clearly not names:
Derkleine, Derwächter, Niemanden

Probably family names, instead of first names:
Schindler, Stepputtis, Waltraut, Kopp

```{r label, options}

df_others %>%
  filter(otherNames %in% c("Derkleine","Derwächter","Niemanden","Schindler","Stepputtis","Waltraut","Kopp")) %>%
  distinct(Subject,otherNames,otherRel)

```

The participants who provided the three items that are clearly not names were excluded.


```{r Relations, options}

# df %>% group_by(otherRel,otherNames,Subject) %>%
#   summarize %>% ungroup %>% count("Relation_Type" = otherRel)

df_others %>% distinct(Subject,otherRel) %>%
  count(otherRel) #%T>% View

df_others %>%
  filter(otherRel %in% c("Schmarotzer","KrankerTeufel")) %>%
  distinct(Subject,otherNames,otherRel)

```

The two items clearly not relational descriptions ("Schmarotzer" and "KrankerTeufel", German swearwords) belong to the participant who also provided non-name items, and as such already is excluded.

#################################
## Direct Measures Ambivalence ##
#################################

```{r Direct Measures of Ambivalence, options}

df_val %>% group_by(otherValence,otherDir) %>%
  summarize(avgDirect = valDir %>% mean)

```

```{r mixed model, options}

afex::set_effects_contrasts()
fitDirect <- df_val %>% filter(subjExclusion %>% not) %>%
  mixed(
    valDir ~ otherDir * otherValence2 + (1|otherValence) + (1|Subject),
    data=., method = "KR",
    check_contrasts = TRUE,
    expand_re=FALSE
  )


fitDirect

summary(fitDirect) %$% coefficients %>% zapsmall #Neat function that puts very small numbers to 0

emmeans(fitDirect,"otherDir") %>% contrast(method="revpairwise")
emmeans(fitDirect,"otherValence2") %>% contrast(method="revpairwise")
emmeans(fitDirect,~otherDir*otherValence2) %>% contrast(method="revpairwise")
compDirect <- emmeans(fitDirect,~otherDir*otherValence2) %>% as_tibble

```

```{r graphics, options}

compDirect %>% 
  ggplot(aes(x=otherDir,y=emmean,fill = otherValence2)) +
  geom_col(position=position_dodge2(reverse=TRUE)) +
  guides(fill=guide_legend(reverse=TRUE)) +
  labs(x="Direct Measure",y="Avg Score [0-100]",fill="SO Valence") +
  scale_y_continuous(limits = c(0,100)) +
  scale_x_discrete(limits = c("Pos","Neg","Amb"))

```


```{r SRI, options}

df_val %>% group_by(otherValence2,SRIValence) %>%
  summarize(avgSRI=mean(valSRI))

```

```{r mixed models, options}

afex::set_effects_contrasts()
fitSRI <- df_val %>%
  mixed(
    valSRI ~ SRIValence * otherValence2 + (1|otherSRI) + (1|Subject) + (1|otherValence),
    data=., method = "KR",
    check_contrasts = TRUE,
    expand_re=FALSE
  )

fitSRI

summary(fitSRI) %$% coefficients %>% zapsmall

# emmeans(fitSRI,"SRIValence") %>% contrast(method="revpairwise")
# emmeans(fitSRI,"otherValence2") %>% contrast(method="revpairwise")
emmeans(fitSRI, ~SRIValence * otherValence2) %>% contrast(method="revpairwise")

```

```{r graphics, options}
emmeans(fitSRI, ~SRIValence * otherValence2) %>% as_tibble %>% 
  ggplot(aes(x=SRIValence,y=emmean,fill = otherValence2)) +
  geom_col(position=position_dodge2(reverse=TRUE)) +
  guides(fill=guide_legend(reverse=TRUE)) +
  labs(x="SRI Valence",y="Avg SRI",fill="SO Valence") +
  coord_cartesian(ylim=c(1,6)) +
  scale_y_continuous(breaks=seq(1,6,1))

```


```{r catSRI, options}

df_val %>% distinct(Subject,otherValence,.keep_all=TRUE) %>% 
  group_by(otherValence2,catSRI) %>% tally %>% mutate(Perc = 100*n/sum(n))

df_val %>% distinct(Subject,otherValence,.keep_all=TRUE) %>% 
  group_by(otherValence2,catSRI_ext) %>% tally %>% mutate(Perc = 100*n/sum(n))

```

Interestingly, our negative others are not strictly aversive, and our positive others are not strictly supportive.
More concerning though, is that 5 negative others are rated supportive, indicating a minimum of 1 for upsetting.

This might be an artefact of the SRI, which questions specifically helpfulness and upsettingness, and not other constructs of social relation.

```{r special cats, options}

df_others %>%
  filter(
    (otherValence2 == "Neg" & (catSRI == "supportive" | catSRI_ext == "supportive")) |
      (otherValence2 == "Pos" & (catSRI == "aversive" | catSRI_ext == "aversive"))
  ) %>%
  distinct(
    Subject,otherValence,otherValence2,otherNames,otherRel,otherDir,valDir,catSRI,catSRI_ext
  ) %>%
  arrange(catSRI,otherValence,Subject,otherDir) #%>% View

```

The truly problematic cases are:
Subj 34 -> provided for both otherNeg clearly Pos others [could be an error with encoding]
Subj 58 -> provided for both otherNeg clearly Pos others

```{r label, options}

df_others %>% filter(Subject == 34 | Subject == 58) %>% 
  distinct(Subject,otherValence2,otherNames,otherRel,otherDir,valDir,catSRI,catSRI_ext,FirstOthers) %>%
  arrange(Subject,otherValence2,otherNames,otherDir) #%>% View

```

These subjects provided only overwhelmingly positive participants.


```{r Graph, options}

df_val %>% spread(otherDir,valDir) %>%
  ggplot(aes(x=Pos,y=Neg,colour=otherValence2,size=Amb)) +
  geom_point(alpha=.15,position=position_dodge2(width=0,reverse=TRUE)) +
  labs(title="Direct Measures of Positivity, Negativity, & Ambivalence",
    x="Positivity",y="Negativity"
    ) +
  guides(
    colour = guide_legend(title="Valence",override.aes = list(alpha=1,size=5),reverse=TRUE),
    size = guide_legend(title="Ambivalence")
    )

df_val %>%
  ggplot(aes(x=otherDir,y=valDir,colour=otherValence2)) +
  geom_point(alpha=.1,position=position_dodge2(width = .75,reverse=TRUE)) +
  labs(x = "Direct Measures", y = "Ratings", title="Direct Measures of SOs") +
  guides(colour = guide_legend(title="Valence" ,override.aes = list(alpha=1,size=5),reverse=TRUE))

df_val %>% group_by(SRIValence,Subject,otherValence,otherValence2) %>%
  summarize(valSRI = mean(valSRI)) %>%
  spread(SRIValence,valSRI) %>%
  ggplot(aes(x=Helpful,y=Upsetting,colour=otherValence2)) +
  geom_jitter(alpha=.3,size=3) +
  labs(title="Social Relationship Index (SRI) Scores", x="Helpfulness",y="Upsettingness") +
  scale_x_continuous(breaks=seq(1,6)) +
  scale_y_continuous(breaks=seq(1,6)) +
  guides(colour = guide_legend(title = "Valence", override.aes=list(alpha=1,size=5), reverse=TRUE))
  
df_val %>% spread(otherDir,valDir) %>%
  ggplot(aes(x=Pos,y=Neg,colour=otherValence2,size=Amb,shape=catSRI_ext)) +
  geom_point(alpha=.15,position=position_dodge2(width=0,reverse=TRUE),stroke=1.5) +
  labs(title="Grid of Direct Measures",x="Positivity",y="Negativity") +
  scale_shape_manual(values=c(1,0,5,2)) +
  guides(
    colour = guide_legend(title="Valence",override.aes = list(alpha=1,size=3),reverse=TRUE),
    shape = guide_legend(
      title="SRI category",
      override.aes = list(alpha=1,size=3,stroke=1,fill="black")),
    size = guide_legend(title="Ambivalence")
  )

```

```{r label, options}

df_val %>% spread(otherDir,valDir) %>% 
  filter(otherValence2 == "Pos" & Neg >= 50 & Pos <= Neg) %>%
  distinct(Subject,otherValence,catSRI,catSRI_ext,Amb,Neg,Pos) #%>% View

df_val %>% spread(otherDir,valDir) %>%
  filter(otherValence2 == "Neg" & Pos >= 50 & Neg <= Pos) %>%
  distinct(Subject,otherValence,catSRI,catSRI_ext,Amb,Neg,Pos) #%>% View

```



###########
# Stimuli #
###########

The positive adjective targets were:
BELIEBT GENIAL GESUND LEBENDIG OPTIMAL PERFEKT SONNIG SUPER

The negative adjective targets were:
BRUTAL EINSAM ELEND GRAUSAM ILLEGAL KRANK TRAGISCH TRAURIG

```{r Targets, options}

# bawlTargets <- bawl %>% 
#   filter(
#     WORD %in% c("BELIEBT","GENIAL","GESUND","LEBENDIG","OPTIMAL","PERFEKT","SONNIG","SUPER") |
#       WORD %in% c("BRUTAL","EINSAM","ELEND","GRAUSAM","ILLEGAL","KRANK","TRAGISCH","TRAURIG")
#   ) %>% mutate(POSITIVE = EMO_MEAN > 0) %>%
#   select(WORD,POSITIVE,EMO_MEAN,EMO_STD,AROUSAL_MEAN,AROUSAL_STD,IMAGE_MEAN,IMAGE_STD,LETTERS,`Ftot/1MIL`) %>%
#   arrange(POSITIVE,WORD)

```

The positive noun primes were:
Mut Lust Glück Freude Frieden Hoffnung Vertrauen Wochenende

The negative noun primes were:
Not Leid Feind Streit Drohung Abschied Gefängnis Verbrechen

```{r Primes, options}

# bawlPrimes <- bawl %>% 
#   filter(
#     WORD_LOWER %in% c("mut","lust","glück","freude","frieden","hoffnung","vertrauen","wochenende") |
#       WORD_LOWER %in% c("not","leid","feind","streit","drohung","abschied","gefängnis","verbrechen")
#   ) %>% mutate(POSITIVE = EMO_MEAN > 0) %>%
#   select(WORD,POSITIVE,EMO_MEAN,EMO_STD,AROUSAL_MEAN,AROUSAL_STD,IMAGE_MEAN,IMAGE_STD,LETTERS,`Ftot/1MIL`) %>%
#   arrange(POSITIVE,WORD)

```

#################
# Main Analyses #
#################

```{r Control, options}

df_trials %>% count(Subject) %$% unique(n) %>%
  paste("Each subject viewed a total of",.,"trials.")

df_trials %>% filter(Subject == 1) %>% count(primeType)

df_trials %>% filter(Subject == 1) %>% count(targetType)

df_trials %>% filter(Subject == 1) %>% count(primeType,targetType)

```

```{r label, options}

df_trials %>% filter(Inclusion) %>% count(primeType,targetType,Subject) %>% count(n)

```


```{r model with random intercepts for subject and target, cache=TRUE}
# emmeans::emm_options(pbkrtest.limit=8000,lmerTest.limit=8000) # Trying it here
afex::set_effects_contrasts()
fitAfex <- df_trials %>% filter(Inclusion) %>% {
  mixed(
    logRT ~ primeType * targetType + (1|Target) + (1|Subject),
    data=., method = "KR",
    check_contrasts = TRUE,
    expand_re=FALSE
  )
}

fitAfex

summary(fitAfex) %$% coefficients %>% zapsmall #Neat function that puts very small numbers to 0

emmeans(fitAfex,"targetType") %>% contrast(method="revpairwise")
primeContr <- emmeans(fitAfex,"primeType") %>% contrast(method="revpairwise")
plannedMeans <- emmeans(fitAfex,~primeType*targetType)

plannedContr <- fitAfex %>% emmeans(c("primeType","targetType")) %>%
  contrast(method="revpairwise") %>% as_tibble %>%
  separate(contrast,c("contrastA","contrastB"),sep=" - ") %>%
  separate(contrastA,c("cPrimeA","cTargetA"),sep=",") %>%
  separate(contrastB,c("cPrimeB","cTargetB"),sep=",") %>%
  filter(
    (cPrimeA == "otherNeg" | cPrimeA == "otherPos") & cTargetA == cTargetB
  ) %>% arrange(cPrimeB,cPrimeA,cTargetA)

fullContr <- fitAfex %>% emmeans(c("primeType","targetType")) %>%
  contrast(method="revpairwise") %>% as_tibble %>%
  separate(contrast,c("contrastA","contrastB"),sep=" - ") %>%
  separate(contrastA,c("cPrimeA","cTargetA"),sep=",") %>%
  separate(contrastB,c("cPrimeB","cTargetB"),sep=",") %>%
  arrange(cPrimeB,cPrimeA,cTargetA)

primeContr <- fitAfex %>% emmeans("primeType") %>%
  contrast(method="revpairwise") %>% as_tibble %>%
  separate(contrast,c("contrastA","contrastB"),sep=" - ") %>%
  arrange(contrastA,contrastB)


```

```{r label, options}

plannedContr

fullContr %>%
  filter(cPrimeA==cPrimeB)

fullContr %>%
  filter((cPrimeA == "otherPos" & cPrimeB == "nounNeg" & cTargetA == "adjNeg" & cTargetB == "adjNeg") | (
    cPrimeA == "otherNeg" & cPrimeB == "nounPos" & cTargetA == "adjPos" & cTargetB == "adjPos"))

primeContr

fullContr %>%
  filter(cTargetA == cTargetB) %>%
  filter(
    (cPrimeA == "otherNeg" & cPrimeB == "letterStr" & cTargetA == "adjPos") |
      (cPrimeA == "otherNeg" & cPrimeB == "nounPos" & cTargetA == "adjPos") |
      (cPrimeA == "otherPos" & cPrimeB == "letterStr" & cTargetA == "adjNeg") |
      (cPrimeA == "otherPos" & cPrimeB == "nounNeg" & cTargetA == "adjNeg")
  )

```

############
## Graphs ##
############

```{r label, options}

plannedContr %>%
  group_by(cPrimeA,cPrimeB) %>%
  do(
    plots = ggplot(.,aes(x=cPrimeA,y=estimate,fill=cTargetA)) +
      geom_col(position=position_dodge2(reverse=TRUE)) +
      ggtitle(paste(.$cPrimeA,"-",.$cPrimeB)) +
      labs(x="",y="") +
      scale_x_discrete(labels=NULL,breaks=NULL) +
      scale_y_continuous(breaks=seq(-0.06,.12,.02) ,limits=c(-0.03,.13)) +
      geom_label(
        aes(
          label=case_when(
            p.value < .001 ~ '***',
            p.value < .01 ~ '**',
            p.value < .05 ~ '*',
            TRUE ~ NA_character_
          )
        ),position = position_dodge2(width=.9,reverse=TRUE))+
      # guides(fill=guide_legend(reverse=TRUE)) +
      theme(legend.position="none")
  ) %$% 
  list(
    plot_grid(
      plotlist=plots,align="hv",nrow=2),
    get_legend(
      ggplot(plannedContr,aes(x=cPrimeA,y=estimate,fill=cTargetA)) +
        geom_col() +
        guides(fill=guide_legend(title="Target",reverse=TRUE))
    )
  ) %>%
  plot_grid(
    plotlist = .,
    rel_widths = c(3,.5)
  ) %>%
  plot_grid(
    ggdraw() + draw_label("Comparisons of Prime Conditions",fontface="bold"),
    .,
    ncol=1, rel_heights = c(0.1,1)
  )

```

```{r label, options}

plannedMeans %>% as_tibble %>% mutate(rt = emmean %>% exp) %>%
  ggplot(aes(x=primeType,y=rt,fill=targetType)) +
  geom_col(position=position_dodge2(reverse=TRUE)) +
  labs(x="Primes",y="Reaction Times (ms)") +
  guides(fill=guide_legend(title="Target",reverse=TRUE)) +
  scale_fill_manual(values=c('#00BFC4','#F8766D'),labels=c('Negative','Positive')) +
  geom_label(data = fullContr %>% filter(cPrimeA==cPrimeB),
             aes(x=cPrimeA,y=1,label=case_when(
               p.value < .001 ~ '***',
               p.value < .01 ~ '**',
               p.value < .05 ~ '*',
               TRUE ~ NA_character_
             )),
             inherit.aes = FALSE)

# ggplot_build(plot)$data -> shows info about plot

```

```{r label, options}

quickplot <- function(data){
  ggplot(data=data,
         aes(x=primeType,y=emmean,fill=targetType,
             ymin=asymp.LCL,ymax=asymp.UCL,
             colour=Condition,size=ifelse(Condition=="Congruent",1,0))
         ) +
    geom_col(position=position_dodge2(reverse=TRUE)) +
    labs(x=NULL,y="Reaction Times (ms)") +
    guides(fill=guide_legend(title="Target\nValence",reverse=TRUE),
           colour=FALSE,size=FALSE) +
    scale_fill_manual(values=c('#00BFC4','#F8766D'),labels=c('Negative','Positive')) +
    theme(plot.margin = unit(c(1.4,0.4,0.4,0.4), "cm")) +
    geom_errorbar(position=position_dodge2(padding=.8,reverse=TRUE),
                  colour="black",size=.5) +
    scale_y_continuous(limits=c(0,820),expand=c(0,0,0.05,0)) +
    scale_colour_manual(values=c("black","white")) +
    scale_size_identity()
}


plannedMeans %>% as_tibble %>%
  mutate_at(
    vars(emmean,asymp.LCL,asymp.UCL),
    .funs=exp) %>%
  mutate(
    primeType = 
      primeType %>%
      recode_factor(
        otherPos = "Positive\nSign. Others",
        otherNeg = "Negative\nSign. Others",
        nounPos = "Univalent\nPositive",
        nounNeg = "Univalent\nNegative",
        letterStr = "Neutral\nLetters"
      ),
    Condition = 
      case_when(
        grepl("Neg",primeType) & grepl("Neg",targetType) ~ "Congruent",
        grepl("Pos",primeType) & grepl("Pos",targetType) ~ "Congruent",
        TRUE ~ "Incongruent"
      )
  ) %>%
  {
    plot_grid(
      plot_grid(
        quickplot(
          filter(.,primeType %in% c("Positive\nSign. Others","Neutral\nLetters"))
        ) + theme(legend.position="none"),
        quickplot(
          filter(.,primeType %in% c("Negative\nSign. Others","Neutral\nLetters"))
        ) + theme(
          legend.position="none",
          axis.line.y = element_blank(),
          axis.ticks.y = element_blank(),
          axis.title.y = element_blank(),
          axis.text.y = element_blank()
        ),
        quickplot(
          filter(.,primeType %in% c("Positive\nSign. Others","Univalent\nNegative"))
        ) + theme(legend.position="none"),
        quickplot(
          filter(.,primeType %in% c("Negative\nSign. Others","Univalent\nPositive"))
        ) + theme(
          legend.position="none",
          axis.line.y = element_blank(),
          axis.ticks.y = element_blank(),
          axis.title.y = element_blank(),
          axis.text.y = element_blank()
        ),
        rel_widths = c(1,.8),
        rel_heights = c(1,1)
      ),
      get_legend(quickplot(.)),
      rel_widths = c(1,.2)
    )
  }


```


####################################
## Interactions Pos-Neg Separated ##
####################################

```{r label, options}
afex::set_effects_contrasts()
fitIntOther <- df_trials %>%
  filter(Inclusion & c(primeType %in% c('otherPos','otherNeg'))) %>%
  mixed(
    logRT ~ primeType * targetType + (1|Target) + (1|Subject),
    data=., method = "KR",
    check_contrasts = TRUE,
    expand_re=FALSE
  )

afex::set_effects_contrasts()
fitIntNoun <- df_trials %>%
  filter(Inclusion & c(primeType %in% c('nounPos','nounNeg'))) %>%
  mixed(
    logRT ~ primeType * targetType + (1|Target) + (1|Subject),
    data=., method = "KR",
    check_contrasts = TRUE,
    expand_re=FALSE
  )

fitIntOther %>% summary

fitIntNoun %>% summary

```

```{r graphs, options}

graphIntOthers <- fitIntOther %>% emmeans(~primeType:targetType) %>% as_tibble %>%
  mutate_at(
    .vars = vars(emmean,asymp.LCL,asymp.UCL),
    .funs = exp
  ) %>%
  select(-c(SE,df)) %>%
  mutate(
    targetType = recode_factor(
      targetType,
      "adjPos" = "Positive",
      "adjNeg" = "Negative"
    ),
    primeType = recode_factor(
      primeType,
      "otherPos" = "Positive",
      "otherNeg" = "Negative"
    ),
    Condition = if_else(
      primeType == targetType,
      "Congruent",
      "Incongruent"
    )
  ) %>%
  ggplot(aes(x=primeType,y=emmean,fill=targetType,
             colour=Condition,ymin=asymp.LCL,ymax=asymp.UCL,
             size=ifelse(Condition=="Congruent",1,0))) +
  geom_col(position=position_dodge2()) +
  geom_errorbar(position=position_dodge2(padding=.8),
                colour="black",size=.5) +
  scale_colour_manual(values=c("black","white"),aesthetics = c("colour")) +
  scale_y_continuous(limits=c(0,820),expand=c(0,0,0.05,0)) +
  scale_size_identity() +
  guides(fill=guide_legend(title="Target\nValence"),
         colour=FALSE,size=FALSE) +
  labs(x="Prime Valence",y="Reaction Time (ms)",title="Significant Other Primes")

graphIntNoun <- fitIntNoun %>% emmeans(~primeType:targetType) %>% as_tibble %>%
  mutate_at(
    .vars = vars(emmean,asymp.LCL,asymp.UCL),
    .funs = exp
  ) %>%
  select(-c(SE,df)) %>%
  mutate(
    targetType = recode_factor(
      targetType,
      "adjPos" = "Positive",
      "adjNeg" = "Negative"
    ),
    primeType = recode_factor(
      primeType,
      "nounPos" = "Positive",
      "nounNeg" = "Negative"
    ),
    Condition = if_else(
      primeType == targetType,
      "Congruent",
      "Incongruent"
    )
  ) %>%
  ggplot(aes(x=primeType,y=emmean,fill=targetType,colour=Condition,
             ymin=asymp.LCL,ymax=asymp.UCL,
             size=ifelse(Condition=="Congruent",1,0))) +
  geom_col(position=position_dodge2()) +
  geom_errorbar(position=position_dodge2(padding=.8),
                colour="black",size=.5) +
  scale_colour_manual(values=c("black","white"),aesthetics = c("colour")) +
  scale_y_continuous(limits=c(0,820),expand=c(0,0,0.05,0)) +
  scale_size_identity() +
  guides(fill=guide_legend(title="Target\nValence"),
         colour=FALSE,size=FALSE) +
  labs(x="Prime Valence",y="Reaction Time (ms)",title="Univalent Noun Primes")

plot_grid(
  graphIntOthers +
    guides(fill=FALSE) +
    labs(title="",x="Significant Other Primes"),
  NULL,
  graphIntNoun +
    guides(fill=FALSE) +
    labs(title="",x="Univalent Noun Primes") +
    theme(
      axis.line.y = element_blank(),
      axis.ticks.y = element_blank(),
      axis.title.y = element_blank(),
      axis.text.y = element_blank()
    ),
  NULL,
  get_legend(graphIntOthers),
  nrow = 1,
  rel_widths = c(1,-.1,.85,-.075,.25),
  rel_heights = c(1,.2)
  ) +
  draw_label("Interaction Comparison",x=.5,y=.95,size=18)

```

#######################
# Additional Analyses #
#######################

```{r mixed Ambivalence, options}

afex::set_effects_contrasts()
ambRT <- left_join(
  df_trials %>% filter(subjExclusion %>% not & primeType %in% c('otherPos','otherNeg')),
  df_val %>% spread(otherDir,valDir) %>% select(Subject,otherValence,otherValence2,Amb,Neg,Pos),
  by=c("Subject","otherValence")
) %>% distinct(Subject,Trial,logRT,otherValence,otherValence2,Target,targetType,Amb,Inclusion) %>%
  filter(Inclusion) %>%
  mixed(
    logRT ~ Amb * otherValence2 + (1|Target) + (1|targetType) + (1|Subject),
    data=.
  )

afex::set_effects_contrasts()
ambOther <- df_val %>% spread(otherDir,valDir) %>%
  mixed(
    Amb ~ otherValence2 + (1|Subject),
    data=.
  )

ambUni <- df_val %>% spread(otherDir,valDir) %>%
  mixed(
    Amb ~ Pos * Neg + (1|Subject) + (1|otherValence2),
    data=.
  )

afex::set_effects_contrasts()
ambUniOther <- df_val %>% spread(otherDir,valDir) %>%
  mixed(
    Amb ~ Pos * Neg * otherValence2 + (1|Subject),
    data=.
  )

afex::set_effects_contrasts()
ambPosOther <- df_val %>% spread(otherDir,valDir) %>%
  mixed(
    Amb ~ Pos * otherValence2 + (1|Subject) + (1|Neg),
    data=.
  )

afex::set_effects_contrasts()
ambNegOther <- df_val %>% spread(otherDir,valDir) %>%
  mixed(
    Amb ~ Neg * otherValence2 + (1|Subject) + (1|Pos),
    data=.
  )

```

```{r label, options}

ambOther %>% emmeans("otherValence2") %>% contrast(method="revpairwise")

ambUni %>% summary %$% coefficients %>% as.data.frame %>%
  rownames_to_column %>% as_tibble


ambUniOther %>% emmeans(~otherValence2+Pos*Neg) %>% contrast

ambUni %>% emmip(Pos~Neg, cov.reduce = range)


ambPosOther %>% emmip(otherValence2~Pos,cov.reduce=range)

ambNegOther %>% emmip(otherValence2~Neg,cov.reduce=range)

ambUniOther %>% emmip(Pos~Neg|otherValence2, cov.reduce = range)

```

```{r plot, options}

df_val %>%
  ggplot(aes(y=valDir,x=otherValence2)) +
  geom_jitter(alpha=.3)+
  facet_grid(otherDir ~ catSRI) +
  theme_bw()

df_val %>%
  ggplot(aes(y=valDir,x=otherValence2)) +
  geom_jitter(alpha=.3)+
  facet_grid(otherDir ~ catSRI_ext) +
  theme_bw()

```

```{r SRI by Direct, options}

# What about centering (of Amb, Neg, Pos) here? Especially as we forego Subject

catSRIFit <- df_val %>% spread(otherDir,valDir) %>%
  distinct(Subject,otherValence,otherValence2,Pos,Neg,Amb,catSRI,catSRI_ext) %>%
  mutate(
    catSRI=factor(catSRI,levels=c('supportive','indifferent','ambivalent','aversive'))
    ) %>%
  multinom(
    catSRI ~ otherValence2 + Amb + Neg + Pos,
    data=.,
    contrasts = "contr.poly"
  )

catSRI_extFit <- df_val %>% spread(otherDir,valDir) %>%
  distinct(Subject,otherValence,otherValence2,Pos,Neg,Amb,catSRI,catSRI_ext) %>%
  mutate(
    catSRI_ext=factor(catSRI_ext,levels=c('supportive','indifferent','ambivalent','aversive'))
    ) %>%
  multinom(
    catSRI_ext ~ otherValence2 + Amb + Neg + Pos,
    data=.,
    contrasts = "contr.poly"
  )

```

