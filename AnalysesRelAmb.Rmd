---
Title:  "Analyses RelAmb"
Author: "Thomas Verliefde"
Date:   "2019-01-08"
Output: html_document
editor_options: 
  chunk_output_type: console
version: "0.5"
---

```{r setup, options}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
```

```{r libraries, options}
lapply(
  c("plyr","dplyr","tidyr","ggplot2","readxl","readr","lme4","afex","lmerTest","pbkrtest","magrittr"),
  require,
  character.only = T
)
```

#############################
# Importing & Cleaning Data #
#############################

Make sure the relevant datafiles (Data_RelAmb.zip and BAWL-R.xls) are in the working directory.

```{r BAWL-R.xls, options}

bawl <- "BAWL-R.xls" %>% read_excel %>%
  mutate(
    WORD_CLASS = recode(
      WORD_CLASS,
      "N" = "NOUN",
      "V" = "VERB",
      "A" = "ADJ"
    )
  )


```

```{r Data_RelAmb.zip, message=FALSE}

temp <- tempdir()
df_raw <- "Data_RelAmb.zip" %>% {
  ldply(
    .data = unzip(.,list=T) %>% filter(grepl("(.csv)$",.$Name)) %$% Name,
    .fun = function(x) unzip(.,files=x,exdir=temp) %>% read_csv
  )
}
rm(temp)

```


This part cleans the data up a lot, and puts it in an useable long format.

A few variables are dropped, as they are not crucial for the current investigations.
The data for each trial (both practice and experiment) is put in long format.
The data for each significant other is put in long format.
The information about block(practice/experiment), trialnr, and descriptives (Answer,Prime, primeType, Target, targetType, RT).
Descriptives is spread out again, to have columns for each.
Some variables are renamed.
Some variables are mutated:
  Many are transformed to strings or numericals
  primeType & targetType get clear non-numerical labels
  primeValence is created to reflect the valence of the primes (regardless of nouns or others)
  Condition shows congruent or incongruent trials (or base, for neutral stimuli)
  Correct indicates whether the target was correctly classified
  Inclusion sets whether or not the trial should be included
    Note: we should still implement exclusion of low acc participants # tried implementing, not yet ready
  LogRT is a simple transformation of RT to it's natural logarithm.

```{r cleaning & gathering, options}

df <- df_raw %>% 
  select(
    -c(practicePrimes,practiceTrials,experimentPrimes,experimentTrials,hostName)
  ) %>%
  gather(
    "fullTrials",
    "trialsOutput",
    matches("^([a-z])+_(\\d)+_([a-z])+$") # This regex matches things with structure: abcd*_123*_abcd*
  ) %>%
  gather(
    "fullOthers",
    "otherOutput",
    matches("^(other)(Pos|Neg)(1|2)") # This regex matches: otherPos1*, otherPos2*¨, otherNeg1*, or otherNeg2*
  ) %>%
  separate(
    fullTrials,
    c("Block","Trial","Desc"),
    sep = "_"
  ) %>%
  spread(
    key = Desc, value = trialsOutput
  ) %>%
  separate(
    fullOthers,
    c("otherValence","Desc"),
    sep = "_",
    extra = "merge",
    fill = "right"
  ) %>%
  mutate(
    Desc = Desc %>% replace_na("otherNames") # alternatively, we could use coalesce.
  ) %>%
  spread(
    key = Desc, value = otherOutput
  ) %>%
  gather(
    "otherDir",
    "valDir",
    matches("^(Dir_)")
  ) %>%
  gather(
    "otherSRI",
    "valSRI",
    matches("^(SRI_)")
  ) %>%
  gather(
    "pointTime",
    "valTime",
    matches("^(time.)")
  ) %>%
  mutate_at(
    vars(otherDir,otherSRI,pointTime),
    funs(gsub("(^.{4})|(\\d)","",.))
  ) %>%
  separate(
    otherSRI,
    c("SRIValence"),
    sep = "_",
    extra = "drop",
    remove=FALSE
  ) %>%
  rename(
    Answer = answer,
    Prime = prime,
    primeType = primeCat,
    Target = target,
    targetType = targetCat,
    otherNum = Num,
    otherRel = Rel,
    RT = time
  ) %>%
  mutate_at(
    vars(Subject,Trial,RT,Age,otherNum,valDir,valSRI,valTime),
    as.numeric
  ) %>%
  filter(Block == "experiment") %>% # drop all practice trials
  group_by(Subject) %>%
  mutate(
    Gender = recode(
      Gender,
      "männlich" = "male",
      "weiblich" = "female"
    ),
    Language = recode(
      Language,
      "Deutsch" = "germanLang",
      "Sonstiges" = "otherLang"
    ),
    Handedness = recode(
      Handedness,
      "rechts" = "rightHand",
      "links" = "leftHand",
      "beide" = "bothHands"
    ),
    primeType = recode(
      primeType,
      `0`= "nounPos",
      `1`= "nounNeg",
      `2`= "otherPos",
      `3`= "otherNeg",
      `4`= "letterStr"
    ) %>% as.factor,
    targetType = recode(
      targetType,
      `0` = "adjPos",
      `1` = "adjNeg"
    ),
    primeValence = case_when(
      grepl("Pos$",primeType) ~ "Pos",
      grepl("Neg$",primeType) ~ "Neg",
      TRUE ~ "Base"
    ) %>% as.factor,
    primeSource = gsub("^(noun|other|letter)(Pos|Neg|Str)$","\\1",primeType) %>% as.factor,
    otherValence = gsub("^(other)(Pos|Neg)(\\d)$","\\2",otherValence),
    Condition = case_when(
      primeValence == "Pos" & targetType == "adjPos" ~ "Congruent",
      primeValence == "Neg" & targetType == "adjNeg" ~ "Congruent",
      primeValence == "Base" ~ "Base",
      TRUE ~ "Incongruent"
    ) %>% as.factor,
    Condition2 = interaction(
      primeSource,Condition,drop=TRUE,sep="",lex.order=TRUE
    ),
    lagPrime = case_when(
      lag(primeType) == primeType~ "Congruent",
      TRUE ~ "Incongruent"),
    lagSource = case_when(
      lag(primeSource) == primeSource~ "Congruent",
      TRUE ~ "Incongruent"),
    lagValence = case_when(
      lag(primeValence) == primeValence~ "Congruent",
      TRUE ~ "Incongruent"),
    lagCondition = case_when(
      lag(Condition) == Condition ~ "Congruent",
      TRUE ~ "Incongruent"),
    Correct = case_when(
      Key == "Apos" & targetType == "adjPos" & Answer == "A" ~ TRUE,
      Key == "Apos" & targetType == "adjNeg" & Answer == "L" ~ TRUE,
      Key == "Aneg" & targetType == "adjNeg" & Answer == "A" ~ TRUE,
      Key == "Aneg" & targetType == "adjPos" & Answer == "L" ~ TRUE,
      TRUE ~ FALSE
    ),
    Accuracy = mean(Correct), # Because we grouped by subject, these means are computed by subject
    speedInclusion = RT >= 300 & RT <= 3000, # Trials with latencies < 300 and > 3000 were excluded
    subjInclusion = 1 - mean(speedInclusion) < 0.83,
      # If we have to exclude more than 83% of the trials of a single participant,
      #  then this participant will be excluded entirely.
    Inclusion = Correct & speedInclusion & subjInclusion,
    logRT = log(RT)
  ) %>%
  ungroup %>%
  arrange(Subject)

```

This part creates a few subdataframes, to keep overview and reduce the amount of replicated rows.
[almost 83000 rows for the full dataset with only 2 participants, due to multiple "gatherings"]

```{r Specific Dataframes, options}

df_subj <- df %>%
  select(
    Subject,Age,Gender,Language,Handedness,Accuracy,subjInclusion,Study,Key,FirstOthers
  ) %>% distinct %>% arrange(Subject)

df_others <- df %>%
  select(
    Subject,Gender,otherValence,otherNames,otherRel,otherNum,otherDir,
    valDir,SRIValence,otherSRI,subjInclusion,Study,Key,FirstOthers
  ) %>% distinct %>% arrange(Subject)

df_time <- df %>%
  select(
    Subject,Gender,pointTime,valTime,subjInclusion
  ) %>% distinct %>% arrange(Subject)

df_trials <- df %>%
  select(
    Subject,Trial,RT,logRT,Prime,primeType,primeSource,primeValence,Target,targetType,Condition,Condition2,
    Answer,Correct,speedInclusion,subjInclusion,Inclusion,Accuracy,Gender,Key,FirstOthers,Handedness
  ) %>% distinct %>% arrange(Subject,Trial)

```


#######################
# Demographics & More #
#######################

```{r Inclusions, options}

df_trials %>% group_by(Subject) %>% summarize(
  "excl" = Correct %>% not %>% mean(na.rm=T)
) %$% mean(excl) %>% multiply_by(100) %>% signif(5) %>%
  paste0(.,"% of trials were excluded because they were incorrectly categorized.")

df_trials %>% group_by(Subject) %>% summarize(
  "excl" = speedInclusion %>% not %>% mean(na.rm=T)
) %$% mean(excl) %>% multiply_by(100) %>% signif(5) %>%
  paste0(.,"% of trials were excluded because the response latencies were either too short (<300ms), or too long (>3000ms)") %>%
  cat

df_subj %$% sum(subjInclusion %>% not) %>%
  paste("A total of",.,"participants were fully excluded due to extremes in accuracy and/or latency.") %>%
  cat

df_trials %>% group_by(Subject) %>% summarize("trialInclusion" = Inclusion %>% mean) %>%
  summarize(trialInclusion %>% mean) %>% as.numeric %>% multiply_by(100) %>% signif(5) %>%
  paste("In total,",.,"% of all trials were included.") %>%
  cat

```

```{r Gender; Language; & Handedness, options}

df_subj %>% filter(subjInclusion) %>% {
  bind_rows(
    count(., "Var" = "Total"),
    count(., "Var" = Gender),
    count(., "Var" = Language),
    count(., "Var" = Handedness)
  )
} %>% mutate(
  "%" = extract2(.,1,"n") %>%
    divide_by(n,.) %>%
    multiply_by(100) %>%
    signif(4)
)

```

```{r Age & Accuracy, options}

df_subj %>% filter(subjInclusion) %>% 
  summarize_at(
    vars(Age,Accuracy),
    funs(mean,sd,min,max,.args = list(na.rm=T))
  ) %>% gather("Var","Value") %>% arrange(Var) %>% separate(Var,c("Var","Func"),sep="_") %>%
  spread(Func,Value) %>% select(Var,mean,sd,min,max)

```

```{r Control Variables, options}

df_subj %>% count(Key,FirstOthers,subjInclusion) %>%
  mutate("%" = n %>% divide_by(sum(.)) %>% multiply_by(100))

```

```{r Specific Timings Experiment Duration, options}

df_time %>% filter(subjInclusion) %>% group_by(pointTime) %>%
  summarize_at(
    "valTime",
    funs(mean,sd,min,max,.args=list(na.rm=T))
  )

```

```{r legacy code, eval=FALSE, include=FALSE}

# This code is only here because I am really proud of it, at least the sapply within select.
# It is no longer run, and is replaced by the chunk above.

df %>% mutate(pointTime = gsub("^(.*)$","time\\1",pointTime)) %>%
  distinct(Subject,pointTime,valTime,subjInclusion) %>%
  spread(pointTime,valTime) %>%
  filter(Subject %>% duplicated %>% not & subjInclusion) %>%
  summarize_at(
    vars(matches("^time")),
    funs(mean,sd,min,max,.args=list(na.rm=T))
  ) %>% select(
    sapply(
      c("Other","Practice","Experiment","Explicit","Demographics","Total"),
      matches
    ) # I am actually suprised that this works...
  ) %>% gather("Var","Value") %>% separate(Var,c("Var","Func"),sep="_") %>%
  spread(Func,Value) %>% select(Var,mean,sd,min,max)

```

```{r Study, include=FALSE}

df %>% filter(Subject %>% duplicated %>% not & subjInclusion) %>%
  count(Study)

```

######################
# Significant Others #
######################

Revise to work with the new df_others

```{r Names, options}

df %>% group_by(otherNames,Subject) %>%
  summarize("otherNum" = otherNum %>% mean(na.rm=T)) %>%
  summarize("n" = n(),"otherNum" = otherNum %>% mean(na.rm=T)) %>%
  add_count(n) %>% arrange(nn %>% desc)

```

```{r Relations, options}

df %>% group_by(otherRel,otherNames,Subject) %>%
  summarize %>% ungroup %>% count("Relation_Type" = otherRel)

```

```{r ???, options}

```

#########################
## Differences Pos/Neg ##
#########################

```{r otherValence, options}



```

```{r SRI, options}

```




#################
# Main Analyses #
#################

Check whether Subject needs to be factorial? (fitting it as a random effect should make clear that it is nonnumeric)

I would like to implement a Bayesian method as well. (e.g. through BayesFactor)


Perhaps use multcomp package to setup pairwise comparisons? (through e.g. cld())
Or with lsmeans or with mvtnorm?

Also perhaps using the afex package (with e.g. mixed() )

Also pbkrtest (with KRmodcomp)

? https://thebiobucket.blogspot.com/2011/06/glmm-with-custom-multiple-comparisons.html#more

Might need glmer instead of lmer?

Through lmerTest we get Satterwaithe?
Also, lmerTest::ls_means() can apply kenward-roger method of degrees of freedom
! ls_means requires factors !

Note, lmerTest::lmer provides t-tests through Satterthwaite's method

Condition2 instead of primeType * Condition, I'd say

```{r Multilevel Models, options}

df_trials %>% filter(Inclusion) %>% {
  fitNull <<- lmer(
    logRT ~ 1 + (1|Target) + (Condition2|Subject), data=., REML = TRUE
  )
  # fitType <<- lmer(
  #   logRT ~ primeType * Condition + (1|Subject), data=., REML=TRUE
  # )
  fitJudd <<- lmer(
    logRT ~ Condition2 + (1|Target) + (Condition2|Subject), data=., REML=TRUE
  )
  # fitSource <<- lmer(
  #   logRT ~ primeSource * Condition + (1|Subject), data=., REML=TRUE
  # )
}

summary(fitJudd)
KRmodcomp(fitJudd, fitNull) # for Kenward-Roger approximate F-test

```

Seems to do the same as lmerTest::lmer and then KRmodcomp, although I am not exactly sure

```{r Afex, options}

df_trials %>% filter(Inclusion) %>% {
  fitAfex <<- mixed(
    logRT ~ Condition2 + (1|Target) + (Condition2|Subject), data=., method="KR",
    check_contrasts=FALSE)
}

anova(fitAfex)
summary(fitAfex)
```


########################
# Exploratory Analyses #
########################